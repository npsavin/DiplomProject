{result:[{name : "CVE-2014-0100",
symptom : "What happens is that after a fragment has been added to the hash chain but before it\'s been added to the lru_list (inet_frag_lru_add), it may get deleted (either by an expired timer if the system load is high or the timer sufficiently low, or by the fraq_queue function for different reasons) before it\'s added to the lru_list, then after it gets added it\'s a matter of time for the evictor to get to a piece of memory which has been freed leading to a number of different bugs depending on what\'s left there ; > What happens is that after a fragment has been added to the hash chain but > before it\'s been added to the lru_list (inet_frag_lru_add), it may get > deleted (either by an expired timer if the system load is high or the > timer sufficiently low, or by the fraq_queue function for different > reasons) before it\'s added to the lru_list  Sorry ;   > diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c > index bb075fc9a14f..322dcebfc588 100644 > --- a/net/ipv4/inet_fragment.c > +++ b/net/ipv4/inet_fragment.c > @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, >  > atomic_inc(&qp->refcnt); > hlist_add_head(&qp->list, &hb->chain); > + inet_frag_lru_add(nf, qp); > spin_unlock(&hb->chain_lock); > read_unlock(&f->lock);  If I understand correctly your\'re saying that qp can be free\'d on another/cpu timer right after dropping the locks ; But how is it possible? ->refcnt is bumped above when arming the timer (before dropping chain lock), so even if the frag_expire timer fires instantly it should not free qp ; >> What happens is that after a fragment has been added to the hash chain but >> before it\'s been added to the lru_list (inet_frag_lru_add), it may get >> deleted (either by an expired timer if the system load is high or the >> timer sufficiently low, or by the fraq_queue function for different >> reasons) before it\'s added to the lru_list >  > Sorry ; >  >> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c >> index bb075fc9a14f..322dcebfc588 100644 >> --- a/net/ipv4/inet_fragment.c >> +++ b/net/ipv4/inet_fragment.c >> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, >>  >> atomic_inc(&qp->refcnt); >> hlist_add_head(&qp->list, &hb->chain); >> + inet_frag_lru_add(nf, qp); >> spin_unlock(&hb->chain_lock); >> read_unlock(&f->lock); >  > If I understand correctly your\'re saying that qp can be free\'d on > another/cpu timer right after dropping the locks ; But how is it > possible? >  > ->refcnt is bumped above when arming the timer (before dropping chain > lock), so even if the frag_expire timer fires instantly it should not > free qp ; >  > What am I missing? >  > Thanks, > Florian >   inet_frag_kill when called from the IPv4/6 frag_queue function will remove the timer refcount, then inet_frag_put afterwards will drop it to 0 and free it and all of this could happen before the frag was ever added to the LRU list, then it gets added ; This happens much easier for IPv6 because of the dropping of overlapping fragments in its frag_queue function, the point is we need to have the timer\'s refcount removed in any way (it could be the timer itself - there\'s an inet_frag_put in the end, or much easier by the frag_queue function) ; >> What happens is that after a fragment has been added to the hash chain but >> before it\'s been added to the lru_list (inet_frag_lru_add), it may get >> deleted (either by an expired timer if the system load is high or the >> timer sufficiently low, or by the fraq_queue function for different >> reasons) before it\'s added to the lru_list >  > Sorry ; >  >> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c >> index bb075fc9a14f..322dcebfc588 100644 >> --- a/net/ipv4/inet_fragment.c >> +++ b/net/ipv4/inet_fragment.c >> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, >>  >> atomic_inc(&qp->refcnt); >> hlist_add_head(&qp->list, &hb->chain); >> + inet_frag_lru_add(nf, qp); >> spin_unlock(&hb->chain_lock); >> read_unlock(&f->lock); >  > If I understand correctly your\'re saying that qp can be free\'d on > another/cpu timer right after dropping the locks ; But how is it > possible? >  > ->refcnt is bumped above when arming the timer (before dropping chain > lock), so even if the frag_expire timer fires instantly it should not > free qp ; > >> What happens is that after a fragment has been added to the hash chain but > >> before it\'s been added to the lru_list (inet_frag_lru_add), it may get > >> deleted (either by an expired timer if the system load is high or the > >> timer sufficiently low, or by the fraq_queue function for different > >> reasons) before it\'s added to the lru_list > >  > > Sorry ; > >  > >> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c > >> index bb075fc9a14f..322dcebfc588 100644 > >> --- a/net/ipv4/inet_fragment.c > >> +++ b/net/ipv4/inet_fragment.c > >> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, > >>  > >> atomic_inc(&qp->refcnt); > >> hlist_add_head(&qp->list, &hb->chain); > >> + inet_frag_lru_add(nf, qp); > >> spin_unlock(&hb->chain_lock); > >> read_unlock(&f->lock); > >  > > If I understand correctly your\'re saying that qp can be free\'d on > > another/cpu timer right after dropping the locks ; But how is it > > possible? > >  > > ->refcnt is bumped above when arming the timer (before dropping chain > > lock), so even if the frag_expire timer fires instantly it should not > > free qp ; >>>> What happens is that after a fragment has been added to the hash chain but >>>> before it\'s been added to the lru_list (inet_frag_lru_add), it may get >>>> deleted (either by an expired timer if the system load is high or the >>>> timer sufficiently low, or by the fraq_queue function for different >>>> reasons) before it\'s added to the lru_list >>> >>> Sorry ; >>> >>>> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c >>>> index bb075fc9a14f..322dcebfc588 100644 >>>> --- a/net/ipv4/inet_fragment.c >>>> +++ b/net/ipv4/inet_fragment.c >>>> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, >>>>  >>>> atomic_inc(&qp->refcnt); >>>> hlist_add_head(&qp->list, &hb->chain); >>>> + inet_frag_lru_add(nf, qp); >>>> spin_unlock(&hb->chain_lock); >>>> read_unlock(&f->lock); >>> >>> If I understand correctly your\'re saying that qp can be free\'d on >>> another/cpu timer right after dropping the locks ; But how is it >>> possible? >>> >>> ->refcnt is bumped above when arming the timer (before dropping chain >>> lock), so even if the frag_expire timer fires instantly it should not >>> free qp ;  On Mon, 03 Mar 2014 15:43:00 +0100 Nikolay Aleksandrov <nikolay@redhat.com> wrote:   > On 03/03/2014 03:40 PM, Florian Westphal wrote: > > Nikolay Aleksandrov <nikolay@redhat.com> wrote:  [...]  > >> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c > >> index bb075fc9a14f..322dcebfc588 100644 > >> --- a/net/ipv4/inet_fragment.c > >> +++ b/net/ipv4/inet_fragment.c > >> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, > >>  > >> atomic_inc(&qp->refcnt); > >> hlist_add_head(&qp->list, &hb->chain); > >> + inet_frag_lru_add(nf, qp); > >> spin_unlock(&hb->chain_lock); > >> read_unlock(&f->lock); > >   [...]  > >  > inet_frag_kill when called from the IPv4/6 frag_queue function will remove the > timer refcount, then inet_frag_put afterwards will drop it to 0 and free it and > all of this could happen before the frag was ever added to the LRU list, then it > gets added ; This happens much easier for IPv6 because of the dropping of > overlapping fragments in its frag_queue function, the point is we need to have > the timer\'s refcount removed in any way (it could be the timer itself - there\'s > an inet_frag_put in the end, or much easier by the frag_queue function) ; > >> What happens is that after a fragment has been added to the hash chain but > >> before it\'s been added to the lru_list (inet_frag_lru_add), it may get > >> deleted (either by an expired timer if the system load is high or the > >> timer sufficiently low, or by the fraq_queue function for different > >> reasons) before it\'s added to the lru_list > >  > > Sorry ; > >  > >> diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c > >> index bb075fc9a14f..322dcebfc588 100644 > >> --- a/net/ipv4/inet_fragment.c > >> +++ b/net/ipv4/inet_fragment.c > >> @@ -278,9 +278,10 @@ static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf, > >>  > >> atomic_inc(&qp->refcnt); > >> hlist_add_head(&qp->list, &hb->chain); > >> + inet_frag_lru_add(nf, qp); > >> spin_unlock(&hb->chain_lock); > >> read_unlock(&f->lock); > >  > > If I understand correctly your\'re saying that qp can be free\'d on > > another/cpu timer right after dropping the locks ; But how is it > > possible? > >  > > ->refcnt is bumped above when arming the timer (before dropping chain > > lock), so even if the frag_expire timer fires instantly it should not > > free qp ; > What happens is that after a fragment has been added to the hash chain but > before it\'s been added to the lru_list (inet_frag_lru_add), it may get > deleted (either by an expired timer if the system load is high or the > timer sufficiently low, or by the fraq_queue function for different > reasons) before it\'s added to the lru_list, then after it gets added > it\'s a matter of time for the evictor to get to a piece of memory which > has been freed leading to a number of different bugs depending on what\'s > left there",
threat : "",
consequences : "",
countermeasures : "Message ID <1393855520-18334-1-git-send-email-nikolay@redhat.com> Download mbox  |  patch Permalink /patch/325844/ State Changes Requested Delegated to: David Miller Headers show Return-Path: <netdev-owner@vger.kernel.org> X-Original-To: patchwork-incoming@ozlabs.org Delivered-To: patchwork-incoming@ozlabs.org Received: from vger.kernel.org (vger.kernel.org [209.132.180.67]) by ozlabs.org (Postfix) with ESMTP id E5FDD2C00E8 for <patchwork-incoming@ozlabs.org>; Tue, 4 Mar 2014 01:07:29 +1100 (EST) Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand id S1754487AbaCCOH0 (ORCPT <rfc822;patchwork-incoming@ozlabs.org>); Mon, 3 Mar 2014 09:07:26 -0500 Received: from mx1.redhat.com ([209.132.183.28]:23689 \"EHLO mx1.redhat.com\" rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP id S1754126AbaCCOHZ (ORCPT <rfc822;netdev@vger.kernel.org>); Mon, 3 Mar 2014 09:07:25 -0500 Received: from int-mx09.intmail.prod.int.phx2.redhat.com (int-mx09.intmail.prod.int.phx2.redhat.com [10.5.11.22]) by mx1.redhat.com (8.14.4/8.14.4) with ESMTP id s23E7Nma006057 (version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK); Mon, 3 Mar 2014 09:07:23 -0500 Received: from solar.usersys.redhat.com (dhcp-1-127.brq.redhat.com [10.34.1.127]) by int-mx09.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s23E7LJ3029327; Mon, 3 Mar 2014 09:07:21 -0500 From: Nikolay Aleksandrov <nikolay@redhat.com> To: netdev@vger.kernel.org Cc: Nikolay Aleksandrov <nikolay@redhat.com>, Jesper Dangaard Brouer <brouer@redhat.com>, \"David S ; Miller <davem@davemloft.net>   Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>  --- I\'m new to this code, so I\'m not sure if this is the best approach to fix the issue and am open to other suggestions, since I consider the issue quite serious (remotely triggerable) I\'ll be closely monitoring this thread to get it fixed asap ; Don\'t be afraid of making the commit message too long or too verbose :-) Thanks! -- To unsubscribe from this list: send the line \"unsubscribe netdev\" in the body of a message to majordomo@vger.kernel.org More majordomo info at http://vger.kernel.org/majordomo-info.html  Patch diff --git a/net/ipv4/inet_fragment.c b/net/ipv4/inet_fragment.c index bb075fc9a14f..322dcebfc588 100644 --- a/net/ipv4/inet_fragment.c +++ b/net/ipv4/inet_fragment.c @@ -278,9 +278,10 @@  static struct inet_frag_queue *inet_frag_intern(struct netns_frags *nf,  atomic_inc(&qp->refcnt); hlist_add_head(&qp->list, &hb->chain);  + inet_frag_lru_add(nf, qp);  spin_unlock(&hb->chain_lock); read_unlock(&f->lock);  - inet_frag_lru_add(nf, qp); +  return qp; }  patchwork  patch tracking system  "
looses : ""
}]}